{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f4d711",
   "metadata": {
    "tags": [
     "00 - Start Here"
    ]
   },
   "source": [
    "# IT4065C — In‑Class Lab Notebook  \n",
    "## Metadata, Classification Tags, and Data Quality (Server Metrics Dataset)\n",
    "\n",
    "**How to use this notebook (student-friendly):**\n",
    "- Run the notebook **top to bottom**, one cell at a time.\n",
    "- Cells are labeled to match the lab steps (Step 1, Step 2, …).\n",
    "- The notebook handles computations; your job is to **interpret results** and fill the Word template.\n",
    "\n",
    "> Tip: You are not graded on Python. You are graded on the **accuracy of your metadata** and the **quality of your governance reasoning**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dab436b",
   "metadata": {
    "tags": [
     "Step 0 - Setup"
    ]
   },
   "source": [
    "## Step 0 — Setup\n",
    "This cell imports libraries and sets display options.  \n",
    "Run it once at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a19924",
   "metadata": {
    "tags": [
     "Step 0 - Setup"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "pd.set_option(\"display.max_colwidth\", 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a50187",
   "metadata": {
    "tags": [
     "Step 1 - Load Data"
    ]
   },
   "source": [
    "## Step 1 — Load the dataset\n",
    "This loads **M1_data_for_metadata.csv** into a pandas DataFrame named `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225aa472",
   "metadata": {
    "tags": [
     "Step 1 - Load Data"
    ]
   },
   "outputs": [],
   "source": [
    "# If this notebook is in the same folder as the CSV, this will work as-is.\n",
    "# If needed, change the path below (e.g., 'data/M1_data_for_metadata.csv')\n",
    "CSV_PATH = \"M1_data_for_metadata.csv\"\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789c681a",
   "metadata": {
    "tags": [
     "Step 2 - Dataset Exploration"
    ]
   },
   "source": [
    "## Step 2 — Dataset overview (for your template)\n",
    "This gives you the number of rows/columns and a quick summary you can use in **Dataset Overview**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9efd0ad",
   "metadata": {
    "tags": [
     "Step 2 - Dataset Exploration"
    ]
   },
   "outputs": [],
   "source": [
    "rows, cols = df.shape\n",
    "print(f\"Rows: {rows:,}\")\n",
    "print(f\"Columns: {cols:,}\")\n",
    "print(\"\\nColumn names:\")\n",
    "for c in df.columns:\n",
    "    print(f\" - {c}\")\n",
    "\n",
    "print(\"\\nData types (pandas):\")\n",
    "display(df.dtypes.to_frame(\"dtype\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5ec9ac",
   "metadata": {
    "tags": [
     "Step 3 - Sample Data"
    ]
   },
   "source": [
    "## Step 3 — Sample data (first 8 rows)\n",
    "Use this output to take a screenshot for the **Sample Data** section of the Word template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6c05d",
   "metadata": {
    "tags": [
     "Step 3 - Sample Data"
    ]
   },
   "outputs": [],
   "source": [
    "df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00801c6f",
   "metadata": {
    "tags": [
     "Step 4 - Metadata Documentation"
    ]
   },
   "source": [
    "## Step 4 — Column-level metadata table (auto-generated)\n",
    "This creates a table with:\n",
    "- Column Name\n",
    "- Data Type (numeric / categorical / text)\n",
    "- Missing Values (count and %)\n",
    "- Example Values (up to 3)\n",
    "\n",
    "You can **copy/paste** this into your Word template, or export it using the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faba481d",
   "metadata": {
    "tags": [
     "Step 4 - Metadata Documentation"
    ]
   },
   "outputs": [],
   "source": [
    "def classify_dtype(series: pd.Series) -> str:\n",
    "    if pd.api.types.is_numeric_dtype(series):\n",
    "        return \"Numeric\"\n",
    "    # treat low-cardinality strings as categorical\n",
    "    if pd.api.types.is_string_dtype(series) or pd.api.types.is_object_dtype(series):\n",
    "        nunique = series.dropna().nunique()\n",
    "        if nunique <= 50:\n",
    "            return \"Categorical\"\n",
    "        return \"Text\"\n",
    "    return \"Other\"\n",
    "\n",
    "def example_values(series: pd.Series, k: int = 3):\n",
    "    vals = series.dropna().unique()\n",
    "    vals = vals[:k]\n",
    "    # convert numpy types to python types for readability\n",
    "    return [str(v) for v in vals]\n",
    "\n",
    "rows = len(df)\n",
    "meta_rows = []\n",
    "for col in df.columns:\n",
    "    s = df[col]\n",
    "    missing_count = int(s.isna().sum())\n",
    "    missing_pct = (missing_count / rows) * 100\n",
    "    meta_rows.append({\n",
    "        \"Column Name\": col,\n",
    "        \"Description (you write in Word)\": \"\",\n",
    "        \"Data Type\": classify_dtype(s),\n",
    "        \"Missing Values (count)\": missing_count,\n",
    "        \"Missing Values (%)\": round(missing_pct, 1),\n",
    "        \"Example Values (up to 3)\": \", \".join(example_values(s, 3))\n",
    "    })\n",
    "\n",
    "metadata_table = pd.DataFrame(meta_rows)\n",
    "metadata_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c63536",
   "metadata": {
    "tags": [
     "Step 4 - Metadata Documentation"
    ]
   },
   "source": [
    "### Optional: Export the metadata table\n",
    "This exports the auto-generated table to a CSV file you can open in Excel, then copy into Word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb612a",
   "metadata": {
    "tags": [
     "Step 4 - Metadata Documentation"
    ]
   },
   "outputs": [],
   "source": [
    "OUTPUT_META_CSV = \"metadata_table_generated.csv\"\n",
    "metadata_table.to_csv(OUTPUT_META_CSV, index=False)\n",
    "print(f\"Saved: {OUTPUT_META_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79abe76",
   "metadata": {
    "tags": [
     "Step 5 - Data Quality"
    ]
   },
   "source": [
    "## Step 5 — Data quality checks (missingness, duplicates, ranges)\n",
    "Use this section to write **4.1 Overall Data Completeness & Key Issues** and **4.2 Recommendations**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e91201",
   "metadata": {
    "tags": [
     "Step 5 - Data Quality"
    ]
   },
   "outputs": [],
   "source": [
    "# Missingness profile\n",
    "missing = df.isna().sum().to_frame(\"missing_count\")\n",
    "missing[\"missing_%\"] = (missing[\"missing_count\"] / len(df) * 100).round(1)\n",
    "missing = missing.sort_values(\"missing_count\", ascending=False)\n",
    "\n",
    "print(\"Missingness (highest first):\")\n",
    "display(missing)\n",
    "\n",
    "# Quick single-sentence summary helper\n",
    "top_missing = missing[missing[\"missing_count\"] > 0].head(3)\n",
    "if len(top_missing) == 0:\n",
    "    print(\"No missing values detected.\")\n",
    "else:\n",
    "    cols = \", \".join(top_missing.index.tolist())\n",
    "    print(f\"Top columns with missing values: {cols}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd78583f",
   "metadata": {
    "tags": [
     "Step 5 - Data Quality"
    ]
   },
   "outputs": [],
   "source": [
    "# Duplicate row check\n",
    "dup_count = int(df.duplicated().sum())\n",
    "print(f\"Duplicate rows: {dup_count}\")\n",
    "\n",
    "# ID uniqueness check (common governance expectation)\n",
    "if \"ID\" in df.columns:\n",
    "    id_dups = int(df[\"ID\"].duplicated().sum())\n",
    "    print(f\"Duplicate IDs: {id_dups}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b3fb6f",
   "metadata": {
    "tags": [
     "Step 5 - Data Quality"
    ]
   },
   "source": [
    "### Numeric summary (useful for spotting outliers)\n",
    "This helps you identify unusual ranges that could indicate data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccb7f13",
   "metadata": {
    "tags": [
     "Step 5 - Data Quality"
    ]
   },
   "outputs": [],
   "source": [
    "numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "display(df[numeric_cols].describe().T)\n",
    "\n",
    "print(\"\\nTip: If you see extreme min/max values compared to typical values (25%/50%/75%), mention that as a potential outlier issue.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1e15d5",
   "metadata": {
    "tags": [
     "Step 5 - Data Quality"
    ]
   },
   "source": [
    "### Simple outlier flags (IQR rule)\n",
    "This does not 'prove' something is wrong, but it highlights values that deserve attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93fdfb8",
   "metadata": {
    "tags": [
     "Step 5 - Data Quality"
    ]
   },
   "outputs": [],
   "source": [
    "def iqr_outlier_count(series: pd.Series) -> int:\n",
    "    s = series.dropna()\n",
    "    if len(s) < 10:\n",
    "        return 0\n",
    "    q1, q3 = np.percentile(s, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lo = q1 - 1.5 * iqr\n",
    "    hi = q3 + 1.5 * iqr\n",
    "    return int(((s < lo) | (s > hi)).sum())\n",
    "\n",
    "outlier_summary = []\n",
    "for c in numeric_cols:\n",
    "    outlier_summary.append({\"column\": c, \"iqr_outliers\": iqr_outlier_count(df[c])})\n",
    "\n",
    "outlier_summary = pd.DataFrame(outlier_summary).sort_values(\"iqr_outliers\", ascending=False)\n",
    "display(outlier_summary)\n",
    "\n",
    "print(\"\\nUse: If a column has many outliers, recommend validation rules or scaling/normalization depending on the use case.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd1bc59",
   "metadata": {
    "tags": [
     "Step 5 - Data Quality"
    ]
   },
   "source": [
    "### Categorical checks (consistency and value counts)\n",
    "Useful for catching inconsistent labels (e.g., 'Fiber' vs 'FIBER' vs 'fiber')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee02506",
   "metadata": {
    "tags": [
     "Step 5 - Data Quality"
    ]
   },
   "outputs": [],
   "source": [
    "categorical_cols = [c for c in df.columns if metadata_table.set_index(\"Column Name\").loc[c, \"Data Type\"] == \"Categorical\"]\n",
    "\n",
    "for c in categorical_cols:\n",
    "    print(f\"\\n=== {c} ===\")\n",
    "    vc = df[c].astype(\"string\").str.strip().value_counts(dropna=False)\n",
    "    display(vc.head(15))\n",
    "\n",
    "print(\"\\nTip: If you see messy categories (extra spaces, inconsistent casing), recommend standardizing values.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8505e4a",
   "metadata": {
    "tags": [
     "Step 6 - Classification & Stewardship"
    ]
   },
   "source": [
    "## Step 6 — Classification tags and stewardship (write-ups)\n",
    "This section helps you draft the **Classification and Stewardship** part of your report.\n",
    "\n",
    "Fill in the answers in the next cell (short phrases are fine), then run it to produce a clean paragraph you can paste into Word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a732ef6",
   "metadata": {
    "tags": [
     "Step 6 - Classification & Stewardship"
    ]
   },
   "outputs": [],
   "source": [
    "# ---- Student fill-in section ----\n",
    "STRUCTURAL_CLASS = \"Structured\"          # Structured / Semi-Structured / Unstructured\n",
    "SENSITIVITY_CLASS = \"Internal\"           # Public / Internal / Confidential / Restricted\n",
    "REGULATORY_RELEVANCE = \"None\"            # GDPR / HIPAA / PCI / None / Uncertain\n",
    "\n",
    "STRUCTURAL_JUST = \"Tabular CSV with clearly defined columns and data types.\"\n",
    "SENSITIVITY_JUST = \"Operational infrastructure metrics could reveal performance or security posture if widely shared.\"\n",
    "REGULATORY_JUST = \"No direct PII/PHI/PCI fields appear in the dataset, but internal security policy still applies.\"\n",
    "\n",
    "DATA_OWNER_ROLE = \"IT Infrastructure Manager\"\n",
    "DATA_STEWARD_ROLE = \"Systems Operations Analyst\"\n",
    "\n",
    "OWNER_RESP_1 = \"Approves access decisions and intended uses.\"\n",
    "OWNER_RESP_2 = \"Sets retention and sharing policy for the dataset.\"\n",
    "\n",
    "STEWARD_RESP_1 = \"Maintains metadata accuracy and classification tags.\"\n",
    "STEWARD_RESP_2 = \"Monitors data quality and coordinates fixes with engineering teams.\"\n",
    "# --------------------------------\n",
    "\n",
    "print(\"### Classification (paste into Word)\")\n",
    "print(f\"Structural classification: {STRUCTURAL_CLASS} — {STRUCTURAL_JUST}\")\n",
    "print(f\"Sensitivity classification: {SENSITIVITY_CLASS} — {SENSITIVITY_JUST}\")\n",
    "print(f\"Regulatory relevance: {REGULATORY_RELEVANCE} — {REGULATORY_JUST}\")\n",
    "\n",
    "print(\"\\n### Stewardship (paste into Word)\")\n",
    "print(f\"Data Owner (role): {DATA_OWNER_ROLE}. Responsibilities: (1) {OWNER_RESP_1} (2) {OWNER_RESP_2}\")\n",
    "print(f\"Data Steward (role): {DATA_STEWARD_ROLE}. Responsibilities: (1) {STEWARD_RESP_1} (2) {STEWARD_RESP_2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbc63c5",
   "metadata": {
    "tags": [
     "Step 7 - Writing Helpers"
    ]
   },
   "source": [
    "## Step 7 — Draft helper for Section 4.1 (Template paragraph)\n",
    "This cell produces a short draft paragraph for **4.1 Overall Data Completeness & Key Issues** using placeholders you can edit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a278b4f0",
   "metadata": {
    "tags": [
     "Step 7 - Writing Helpers"
    ]
   },
   "outputs": [],
   "source": [
    "# Auto-pick the top missing columns to help you draft 4.1\n",
    "missing_sorted = df.isna().sum().sort_values(ascending=False)\n",
    "top = [c for c in missing_sorted.index if missing_sorted[c] > 0][:3]\n",
    "\n",
    "# Identify numeric vs categorical example columns\n",
    "num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "cat_cols = [c for c in df.columns if not pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "num_ex = num_cols[:2]\n",
    "cat_ex = cat_cols[:2]\n",
    "\n",
    "print(\"Copy/edit this paragraph into your Word template (Section 4.1):\\n\")\n",
    "print(f\"Overall, the dataset contains moderate data completeness. Significant missing values are observed in {', '.join(top) if top else '[no major columns]'}, which may affect performance monitoring and downstream analysis. \"\n",
    "      f\"The dataset includes a mix of quantitative attributes (e.g., {', '.join(num_ex)}) and categorical attributes (e.g., {', '.join(cat_ex)}). \"\n",
    "      \"From a data governance perspective, these quality issues could reduce reliability of operational decisions if not addressed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2788f9c",
   "metadata": {
    "tags": [
     "Step 8 - Wrap Up"
    ]
   },
   "source": [
    "## Step 8 — What to copy into the Word template (quick checklist)\n",
    "\n",
    "From this notebook, you can copy:\n",
    "- Step 2: row/column counts + data types\n",
    "- Step 3: screenshot of first 8 rows\n",
    "- Step 4: metadata table (and missingness counts)\n",
    "- Step 5: quality issues (missingness, outliers, category consistency)\n",
    "- Step 6: classification & stewardship write-up\n",
    "- Step 7: draft paragraph for Section 4.1\n",
    "\n",
    "You still need to write:\n",
    "- Column descriptions (plain language)\n",
    "- 2 quality recommendations (with governance justification)\n",
    "- 2 practical use cases\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
